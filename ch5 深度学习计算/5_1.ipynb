{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3085962-39a2-45f4-a019-13515247e3ef",
   "metadata": {},
   "source": [
    "# 5.1 层和块\n",
    "块（block），层（layer）\n",
    "*从编程的角度来看，块由类（class）表示。它的任何子类都必须定义一个将其输入转换为输出的前向传播函\n",
    "数，并且必须存储任何必需的参数。在定义我们自己的块时，一般我们只需要考虑前向传播函数和必要的参数*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8640e6-237b-4b5a-a5ca-5032fedb3973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1541, -0.1779,  0.0860, -0.0023,  0.2044, -0.0051, -0.0590,  0.0081,\n",
       "          0.1588, -0.1864],\n",
       "        [-0.0716, -0.1415,  0.0373, -0.1479,  0.1410, -0.1132,  0.1019, -0.0542,\n",
       "          0.2021, -0.0589]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256),\n",
    "                    nn.ReLU(), \n",
    "                    nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)\n",
    "# 这里我们通过实例化Sequential来进行构建模型，Sequential是一种特殊的Module也就是一种快"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2bbc9-e5dd-42c6-851f-96a3297a2abd",
   "metadata": {},
   "source": [
    "## 5.1.1 自定义块\n",
    "每一个块必须提供的基本功能：\n",
    "1. 将输入数据作为其前向传播函数的参数\n",
    "2. 通过前向传播函数来生成输出。输出与输入的形状不必相同\n",
    "3. 计算其输出关于输入的梯度，可以通过其反向传播函数进行访问*这常常时自动发生的*\n",
    "4. 存储和访问前向传播计算所需要的参数\n",
    "5. 根据需要初始化模型参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7788be3-eb99-41f5-b830-15cc5be5a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    # 用参数声明层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 隐藏层\n",
    "        self.out = nn.Linear(256, 10) # 输出层\n",
    "\n",
    "    # 定义模型的前向传播\n",
    "    def forward(self, X):\n",
    "        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae47665-5675-420e-88f6-5aa4b44a3d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2541e-01,  1.3199e-01,  2.4315e-04,  6.1485e-02, -6.4898e-02,\n",
       "         -1.6717e-01,  8.3730e-02, -3.2662e-03, -2.3478e-01,  2.3014e-01],\n",
       "        [ 2.3603e-01,  5.3410e-03,  5.3815e-02,  3.8420e-02, -1.1678e-01,\n",
       "         -2.0767e-01,  5.0509e-02, -3.5736e-03, -3.7410e-01,  1.2011e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f98ca8-8f8c-4a58-a464-4757fa4b71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 块具有比较好的结构性，类似于逐层的抽象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f9f3d53-cfe6-44f0-b163-bb4f800764be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顺序块 Sequential类\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
    "            # 变量_modules中。_module的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02c9b57-f5ac-40d8-9e70-c8e06205506b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0357, -0.0949,  0.2539, -0.1732,  0.1989, -0.0606, -0.1905, -0.1554,\n",
       "          0.1482,  0.0725],\n",
       "        [ 0.1042, -0.0578,  0.2320, -0.0969,  0.2381, -0.0446, -0.0996, -0.1626,\n",
       "         -0.0292,  0.2149]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d8d3e-7031-4e18-8e9a-d05aab262940",
   "metadata": {},
   "source": [
    "## 5.1.3 在前向传播函数中执行代码\n",
    "Sequential 使得模型构造变得简单，允许我们组合新的架构**很多时候我们需要更强的灵活性，定义自己的块**，以便于在前向传播中**利用控制流**，或者是使用其他数学运算\n",
    "目前为止，我们网络中的操作对网络的激活值以及网络参数起作用，但是，有时我们希望更新*函数参数*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6b50089-0a5f-4724-a54c-f6354182b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        # 使用创建的常量参数以及relu和mm函数\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        # 复用全连接层。这相当于两个全连接层共享参数\n",
    "        X = self.linear(X)\n",
    "        # 控制流\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0f6718f-0efe-4e44-8e87-ab117d3897ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4425, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218dc9ba-abc6-40e2-a0b7-641c694ee089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
